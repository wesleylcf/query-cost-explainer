{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /usr/local/anaconda3/lib/python3.9/site-packages (2.9.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import logging\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global conn\n",
    "try:\n",
    "  conn = psycopg2.connect(\n",
    "      dbname=\"TPC-H\",\n",
    "      user=\"postgres\",\n",
    "      password=\"password\",\n",
    "      host=\"localhost\",\n",
    "      port=\"5432\"\n",
    "  )\n",
    "  logging.info(\"Database connection established.\")\n",
    "except Exception as e:\n",
    "  print(f\"An error occurred while connecting to the database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "REFRESH_STATS_QUERY = \"\"\"\n",
    "DO $$\n",
    "DECLARE\n",
    "    table_name TEXT;\n",
    "    tables_to_analyze TEXT[] := ARRAY['lineitem', 'orders','customer','partsupp','supplier','part','nation','region'];\n",
    "BEGIN\n",
    "    FOREACH table_name IN ARRAY tables_to_analyze\n",
    "    LOOP\n",
    "        EXECUTE format('ANALYZE %I', table_name);\n",
    "    END LOOP;\n",
    "END $$;\n",
    "\"\"\"\n",
    "\n",
    "RELATION_PROPERTIES_QUERY = \"\"\"\n",
    "SELECT relname, reltuples, relpages \n",
    "FROM pg_class \n",
    "WHERE relkind IN ('r');\n",
    "\"\"\"\n",
    "\n",
    "SETTINGS_QUERY = \"\"\"\n",
    "SELECT relname, current_setting('random_page_cost')::real,current_setting('cpu_index_tuple_cost')::real, current_setting('cpu_operator_cost')::real, current_setting('cpu_tuple_cost')::real, current_setting('seq_page_cost')::real, relpages AS pages, reltuples AS tuples, relallvisible as visible_pages\n",
    "from pg_class;\n",
    "\"\"\"\n",
    "\n",
    "class Explainer:\n",
    "    tableSet = {'lineitem', 'orders','customer','partsupp','supplier','part','nation','region'}\n",
    "    properties = defaultdict(lambda: {})\n",
    "\n",
    "    def __init__(self, conn, debug=False):\n",
    "        self.conn = conn\n",
    "        # self.run(REFRESH_STATS_QUERY)\n",
    "        self.debug = debug\n",
    "\n",
    "        result = self.run(SETTINGS_QUERY)\n",
    "        for relname, random_page_cost, cpu_index_tuple_cost, cpu_operator_cost, cpu_tuple_cost, seq_page_cost, pages, tuples, visible_pages in result:\n",
    "            if relname.split('_')[0] in self.tableSet:\n",
    "                self.properties[relname]['pages'] = pages\n",
    "                self.properties[relname]['visible_pages'] = visible_pages\n",
    "                self.properties[relname]['tuples'] = tuples\n",
    "                self.properties['random_page_cost'] = random_page_cost\n",
    "                self.properties['cpu_index_tuple_cost'] = cpu_index_tuple_cost\n",
    "                self.properties['cpu_operator_cost'] = cpu_operator_cost\n",
    "                self.properties['cpu_tuple_cost'] = cpu_tuple_cost\n",
    "                self.properties['seq_page_cost'] = seq_page_cost\n",
    "\n",
    "        self.cost_estimator = CostEstimator(self.properties)\n",
    "\n",
    "    def run(self, query):\n",
    "        cur = self.conn.cursor()\n",
    "        cur.execute(query)\n",
    "        try:\n",
    "            return cur.fetchall()\n",
    "        except:\n",
    "            logging.warning(f\"No rows fetched for query {query}; Returning []\")\n",
    "            return []\n",
    "\n",
    "    def run_explain(self, query):\n",
    "        \"\"\"\n",
    "        Executes the EXPLAIN command on a given SQL query using a PostgreSQL connection\n",
    "        and returns the JSON-formatted plan.\n",
    "\n",
    "        See 'EXPLAIN' documentation:\n",
    "        https://www.postgresql.org/docs/current/sql-explain.html\n",
    "\n",
    "        See psycopg2 documentation:\n",
    "        https://www.psycopg.org/docs/cursor.html#cursor.execute\n",
    "\n",
    "        Parameters:\n",
    "        query (str): SQL query to be explained.\n",
    "        conn (psycopg2.connection): Active database connection object.\n",
    "\n",
    "        Returns:\n",
    "        list: A list of dictionaries representing the JSON formatted execution plan returned by PostgreSQL.\n",
    "        \"\"\"\n",
    "        with self.conn.cursor() as cur:\n",
    "            # cur.execute(f\"EXPLAIN (ANALYZE true, BUFFERS true, FORMAT json) {query}\")\n",
    "            cur.execute(f\"EXPLAIN (ANALYZE true, FORMAT json) {query}\")\n",
    "            explain_output = cur.fetchone()[0]\n",
    "            logging.info(\"EXPLAIN command executed successfully.\")\n",
    "            # psycopg2 implicitly converts the JSON output to a list of dictionaries (python)\n",
    "            return explain_output\n",
    "\n",
    "    def analyze_node(self, node):\n",
    "        \"\"\"\n",
    "        Analyze a single node within the execution plan, extracting estimated cost metrics from the PostgreSQL planner\n",
    "        ,  and recursively processing any sub-plans.\n",
    "\n",
    "        Parameters:\n",
    "        node (dict): A single node from the JSON execution plan.\n",
    "\n",
    "        Returns:\n",
    "        dict: Node and sub-nodes analysis including both estimated and computed costs.\n",
    "        \"\"\"\n",
    "        estimated_cost, explanation = self.cost_estimator.estimate(node)\n",
    "        \n",
    "        node['explanation'] = explanation\n",
    "        node['estimated_cost'] = estimated_cost\n",
    " \n",
    "        # Add cost of children\n",
    "        if 'Plans' in node:\n",
    "            for child in node['Plans']:\n",
    "                child_node = self.analyze_node(child)\n",
    "                node['estimated_cost'] += child_node['Total Cost']\n",
    "        \n",
    "        node['estimated_cost'] = round(node['estimated_cost'], 2)\n",
    "\n",
    "        error_margin = 0.1\n",
    "        if node['Node Type'] == 'Nested Loop':\n",
    "            error_margin = 0.2\n",
    "        if self.debug and abs(node['estimated_cost'] - node['Total Cost'])/node['Total Cost'] > error_margin:\n",
    "            print(node)\n",
    "            raise Exception(f\"Estimated cost({node['estimated_cost']}) differs from Actual cost({node['Total Cost']}) significantly\")\n",
    "        \n",
    "        return node\n",
    "\n",
    "\n",
    "    def analyze_execution_plan(self, explain_output):\n",
    "        \"\"\"\n",
    "        Initiates the recursive analysis of the entire execution plan from the top-level node.\n",
    "\n",
    "        Parameters:\n",
    "        explain_output (list): The JSON execution plan as a list from PostgreSQL.\n",
    "\n",
    "        Returns:\n",
    "        dict: A dictionary representing the analyzed execution plan including nested sub-plans.\n",
    "        \"\"\"\n",
    "        if explain_output:\n",
    "            # The execution plan is enclosed in a list -> start with the first item\n",
    "            return self.analyze_node(explain_output[0]['Plan'])\n",
    "        else:\n",
    "            logging.error(\"No execution plan found.\")\n",
    "            return {}\n",
    "\n",
    "    def generate_report(self, analysis_results):\n",
    "        \"\"\"\n",
    "        Generates a formatted JSON report from the analysis results.\n",
    "\n",
    "        Parameters:\n",
    "        analysis_results (dict): Analysis results of the execution plan.\n",
    "\n",
    "        Returns:\n",
    "        str: A string representation of the JSON-formatted analysis report.\n",
    "        \"\"\"\n",
    "        report = json.dumps(analysis_results, indent=4)\n",
    "        logging.info(\"Report generated.\")\n",
    "        return report\n",
    "        \n",
    "class CostEstimator:\n",
    "    def __init__(self, properties):\n",
    "        self.properties = properties\n",
    "        self.MATERIALIZED_CONSECUTIVE_ACCESS_COST = 0.0125 # too complex; https://postgrespro.com/blog/pgsql/5969618\n",
    "\n",
    "    def estimate(self, node):\n",
    "        operator = node['Node Type']\n",
    "        if operator == 'Seq Scan':\n",
    "            return self.scan_cost_function(node)\n",
    "        if operator == 'Index Only Scan':\n",
    "            return self.index_only_scan_cost_function(node)\n",
    "        if operator == 'Materialize':\n",
    "            return self.materialize_cost_function(node)\n",
    "        if operator == 'Nested Loop':\n",
    "            return self.nested_loop_cost_function(node)\n",
    "        else:\n",
    "            raise Exception(f\"Cost function is undefined for operator {operator}\")\n",
    "\n",
    "    def nested_loop_cost_function(self, node):\n",
    "        \"\"\"\n",
    "            Assume that they define child plans as a stack(last one executed first)\n",
    "        \"\"\"\n",
    "        materialize_node = scan_node = None\n",
    "        current_rows = node['Plan Rows']\n",
    "\n",
    "        for child in node['Plans']:\n",
    "            if child['Node Type'] == 'Materialize':\n",
    "                materialize_node = child\n",
    "            else:\n",
    "                scan_node = child\n",
    "        \n",
    "        scan_rows, scan_cost = scan_node['Plan Rows'], scan_node['Total Cost']\n",
    "        explanation_array = [f\"Explanation for {node['Node Type']}\"]\n",
    "\n",
    "        consecutive_materialize_access_cost = (scan_rows-1) * self.MATERIALIZED_CONSECUTIVE_ACCESS_COST\n",
    "        materialize_cost = materialize_node['Total Cost'] + consecutive_materialize_access_cost\n",
    "        explanation_array.append(f\"consecutive_materialize_access_cost = scans_row-1({scan_rows-1}) * MATERIALIZED_CONSECUTIVE_ACCESS_COST(0.0125)\")\n",
    "        explanation_array.append(f\"materialize_cost = initial_materialized_access_cost({materialize_node['Node Type']}) + consecutive_materialize_access_cost({consecutive_materialize_access_cost}) = {materialize_cost}\")\n",
    "\n",
    "        explanation_array.append(f\"scan_cost = {scan_cost}\")\n",
    "\n",
    "        output_rows_cost = current_rows * self.properties['cpu_tuple_cost']\n",
    "        explanation_array.append(f\"output_rows_cost = output rows({current_rows}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']}) = {output_rows_cost}\")\n",
    "\n",
    "        total_cost = materialize_cost + scan_cost + output_rows_cost\n",
    "        explanation_array.append(f\"total_cost = materialize_cost({materialize_cost}) + scan_cost({scan_cost}) + output_rows_cost({output_rows_cost}) = {total_cost}\")\n",
    "        \n",
    "        return [output_rows_cost, '\\n'.join(explanation_array)]\n",
    "\n",
    "    def materialize_cost_function(self, node):\n",
    "        rows = node['Plan Rows']\n",
    "        cpu_operator_cost = self.properties['cpu_operator_cost']\n",
    "        total_cost = 2 * cpu_operator_cost * rows\n",
    "        return [total_cost, f\"Materialize cost = 2 * cpu_operator_cost({cpu_operator_cost}) * tuples({rows}) = {total_cost}\"]\n",
    "\n",
    "    def scan_cost_function(self, node):\n",
    "        rows, table_props = node['Plan Rows'], self.properties[node['Relation Name']]\n",
    "        seq_pages_accessed = table_props['pages']\n",
    "        total_cost = (seq_pages_accessed * self.properties['seq_page_cost']) + (rows * self.properties['cpu_tuple_cost'])\n",
    "        explanation = f\"Total cos = seq_pages_accessed({seq_pages_accessed}) * seq_page_cost({self.properties['seq_page_cost']}) + rows({rows}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']}) = {total_cost}\"\n",
    "        return [total_cost, explanation]\n",
    "\n",
    "    def index_only_scan_cost_function(self, node) -> float:\n",
    "        explanation_array = [\"Formula: total_cost = index_access_cost + table_pages_fetch_cost\"]\n",
    "        relation_name, rows = node['Relation Name'], node['Plan Rows']\n",
    "        relation_pages, relation_tuples =  self.properties[relation_name]['pages'], self.properties[relation_name]['tuples']\n",
    "\n",
    "        index_selectivity = rows/relation_tuples\n",
    "        explanation_array.append(\"Calculation for index_access_cost:\")\n",
    "        explanation_array.append(f\"index_selectivity = estimated_rows({rows}) / total_rows({relation_tuples}) = {index_selectivity}\")\n",
    "\n",
    "        estimated_pages, estimated_tuples = relation_pages * index_selectivity, relation_tuples * index_selectivity\n",
    "        explanation_array.append(f\"estimated_pages = selectivity({index_selectivity}) * total pages({relation_pages}) = {estimated_pages}\")\n",
    "        explanation_array.append(f\"estimated_tuples = selectivity({index_selectivity}) * total tuples({relation_tuples}) = {estimated_tuples}\")\n",
    "\n",
    "        estimated_index_pages = self.properties[node['Index Name']]['pages']\n",
    "        random_page_cost, cpu_index_tuple_cost, cpu_operator_cost, cpu_tuple_cost, seq_page_cost = self.properties['random_page_cost'], self.properties['cpu_index_tuple_cost'], self.properties['cpu_operator_cost'], self.properties['cpu_tuple_cost'], self.properties['seq_page_cost']\n",
    "        explanation_array.append(f\"From DB: random_page_cost={random_page_cost} cpu_index_tuple_cost={cpu_index_tuple_cost} cpu_operator_cost={cpu_operator_cost} cpu_tuple_cost={cpu_tuple_cost} seq_page_cost={seq_page_cost}\")\n",
    "        estimated_index_cost = estimated_index_pages * random_page_cost + estimated_tuples * (cpu_index_tuple_cost + cpu_operator_cost)\n",
    "        explanation_array.append(f\"index_access_cost = estimated_index_pages({estimated_pages}) * random_page_cost({random_page_cost}) + estimated_tuples({estimated_tuples}) * (cpu_index_tuple_cost({cpu_index_tuple_cost}) + cpu_operator_cost({cpu_operator_cost})) = {estimated_index_cost}\")\n",
    "        \n",
    "        explanation_array.append(\"Calculation for index_access_cost:\")\n",
    "        frac_visible = self.properties[relation_name]['visible_pages']/relation_pages\n",
    "        explanation_array.append(f\"fraction_pages_visible = relallvisible({self.properties[relation_name]['visible_pages']}) / total_pages({relation_pages}) = {frac_visible}\")\n",
    "        estimated_table_cost = (1-frac_visible) * estimated_pages * seq_page_cost + estimated_tuples * cpu_tuple_cost\n",
    "        explanation_array.append(f\"table_pages_fetch_cost = (1-frac_visible={frac_visible}) * estimated_pages({estimated_pages}) * seq_page_cost({seq_page_cost}) + estimated_tuples({estimated_tuples}) * cpu_tuple_cost({cpu_tuple_cost})\")\n",
    "\n",
    "        estimated_total_cost = estimated_index_cost + estimated_table_cost\n",
    "        explanation_array.append(f\"Therefore total cost = index_access_cost({estimated_index_cost}) + table_pages_fetch_cost({estimated_table_cost}) = {estimated_total_cost}\")\n",
    "        explanation = '\\n'.join(explanation_array)\n",
    "\n",
    "        return [estimated_total_cost, explanation]\n",
    "    \n",
    "    def merge_join_function_cost_function(self, node):\n",
    "        # explanation_array = [\"Formula: total_cost = left_cost + right_cost\"]\n",
    "        # left_rows, right_rows = node['Plan Rows'], node['Plan Rows']\n",
    "        # left_props, right_props = self.properties[node['Relation Name']], self.properties[node['Relation Name']]\n",
    "        # left_pages, right_pages = left_props['pages'], right_props['pages']\n",
    "        # left_tups, right_tups = left_props['tuples'], right_props['tuples']\n",
    "        # left_cost = (left_pages * self.properties['seq_page_cost']) + (left_tups * self.properties['cpu_tuple_cost'])\n",
    "        # right_cost = (right_pages * self.properties['seq_page_cost']) + (right_tups * self.properties['cpu_tuple_cost'])\n",
    "        # explanation_array.append(f\"left_cost = (left_pages({left_pages}) * seq_page_cost({self.properties['seq_page_cost']})) + (left_tups({left_tups}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']})) = {left_cost}\")\n",
    "        # explanation_array.append(f\"right_cost = (right_pages({right_pages}) * seq_page_cost({self.properties['seq_page_cost']})) + (right_tups({right_tups}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']})) = {right_cost}\")\n",
    "        # estimated_total_cost = left_cost + right_cost\n",
    "        # explanation_array.append(f\"Therefore total cost = left_cost({left_cost}) + right_cost({right_cost}) = {estimated_total_cost}\")\n",
    "        # explanation = '\\n'.join(explanation_array)\n",
    "        # return [estimated_total_cost, explanation]\n",
    "        explanation_array = [\"Formula: total_cost = left_cost + right_cost + sort_cost\"]\n",
    "        left_rows, right_rows = node['Plan Rows'], node['Plan Rows']\n",
    "        left_props, right_props = self.properties[node['Relation Name']], self.properties[node['Relation Name']]\n",
    "        left_pages, right_pages = left_props['pages'], right_props['pages']\n",
    "        left_tups, right_tups = left_props['tuples'], right_props['tuples']\n",
    "        left_cost = (left_pages * self.properties['seq_page_cost']) + (left_tups * self.properties['cpu_tuple_cost'])\n",
    "        right_cost = (right_pages * self.properties['seq_page_cost']) + (right_tups * self.properties['cpu_tuple_cost'])\n",
    "        explanation_array.append(f\"left_cost = (left_pages({left_pages}) * seq_page_cost({self.properties['seq_page_cost']})) + (left_tups({left_tups}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']})) = {left_cost}\")\n",
    "        explanation_array.append(f\"right_cost = (right_pages({right_pages}) * seq_page_cost({self.properties['seq_page_cost']})) + (right_tups({right_tups}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']})) = {right_cost}\")\n",
    "        sort_cost = (left_tups + right_tups) * math.log(left_tups + right_tups) * self.properties['cpu_operator_cost']\n",
    "        explanation_array.append(f\"sort_cost = (left_tups({left_tups}) + right_tups({right_tups})) * log(left_tups({left_tups}) + right_tups({right_tups})) * cpu_operator_cost({self.properties['cpu_operator_cost']}) = {sort_cost}\")\n",
    "        estimated_total_cost = left_cost + right_cost + sort_cost\n",
    "        explanation_array.append(f\"Therefore total cost = left_cost({left_cost}) + right_cost({right_cost}) + sort_cost({sort_cost}) = {estimated_total_cost}\")\n",
    "        explanation = '\\n'.join(explanation_array)\n",
    "        return [estimated_total_cost, explanation]\n",
    "    \n",
    "    def hash_join_cost_function(self, node):\n",
    "        # explanation_array = [\"Formula: total_cost = left_cost + right_cost\"]\n",
    "        # left_rows, right_rows = node['Plan Rows'], node['Plan Rows']\n",
    "        # left_props, right_props = self.properties[node['Relation Name']], self.properties[node['Relation Name']]\n",
    "        # left_pages, right_pages = left_props['pages'], right_props['pages']\n",
    "        # left_tups, right_tups = left_props['tuples'], right_props['tuples']\n",
    "        # left_cost = (left_pages * self.properties['seq_page_cost']) + (left_tups * self.properties['cpu_tuple_cost'])\n",
    "        # right_cost = (right_pages * self.properties['seq_page_cost']) + (right_tups * self.properties['cpu_tuple_cost'])\n",
    "        # explanation_array.append(f\"left_cost = (left_pages({left_pages}) * seq_page_cost({self.properties['seq_page_cost']})) + (left_tups({left_tups}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']})) = {left_cost}\")\n",
    "        # explanation_array.append(f\"right_cost = (right_pages({right_pages}) * seq_page_cost({self.properties['seq_page_cost']})) + (right_tups({right_tups}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']})) = {right_cost}\")\n",
    "        # estimated_total_cost = left_cost + right_cost\n",
    "        # explanation_array.append(f\"Therefore total cost = left_cost({left_cost}) + right_cost({right_cost}) = {estimated_total_cost}\")\n",
    "        # explanation = '\\n'.join(explanation_array)\n",
    "        # return [estimated_total_cost, explanation]\n",
    "        explanation_array = [\"Formula: total_cost = left_cost + right_cost + hash_cost\"]\n",
    "        left_rows, right_rows = node['Plan Rows'], node['Plan Rows']\n",
    "        left_props, right_props = self.properties[node['Relation Name']], self.properties[node['Relation Name']]\n",
    "        left_pages, right_pages = left_props['pages'], right_props['pages']\n",
    "        left_tups, right_tups = left_props['tuples'], right_props['tuples']\n",
    "        left_cost = (left_pages * self.properties['seq_page_cost']) + (left_tups * self.properties['cpu_tuple_cost'])\n",
    "        right_cost = (right_pages * self.properties['seq_page_cost']) + (right_tups * self.properties['cpu_tuple_cost'])\n",
    "        explanation_array.append(f\"left_cost = (left_pages({left_pages}) * seq_page_cost({self.properties['seq_page_cost']})) + (left_tups({left_tups}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']})) = {left_cost}\")\n",
    "        explanation_array.append(f\"right_cost = (right_pages({right_pages}) * seq_page_cost({self.properties['seq_page_cost']})) + (right_tups({right_tups}) * cpu_tuple_cost({self.properties['cpu_tuple_cost']})) = {right_cost}\")\n",
    "        smaller_tups = min(left_tups, right_tups)\n",
    "        hash_cost = smaller_tups * self.properties['cpu_operator_cost']\n",
    "        explanation_array.append(f\"hash_cost = smaller_tups({smaller_tups}) * cpu_operator_cost({self.properties['cpu_operator_cost']}) = {hash_cost}\")\n",
    "        estimated_total_cost = left_cost + right_cost + hash_cost\n",
    "        explanation_array.append(f\"Therefore total cost = left_cost({left_cost}) + right_cost({right_cost}) + hash_cost({hash_cost}) = {estimated_total_cost}\")\n",
    "        explanation = '\\n'.join(explanation_array)\n",
    "        return [estimated_total_cost, explanation]\n",
    "    \n",
    "    def unique_cost_function(self, node):\n",
    "        explanation_array = [\"Formula: total_cost = child_cost\"]\n",
    "        child_cost = node['Total Cost']\n",
    "        explanation_array.append(f\"child_cost = {child_cost}\")\n",
    "        estimated_total_cost = child_cost\n",
    "        explanation_array.append(f\"Therefore total cost = child_cost({child_cost}) = {estimated_total_cost}\")\n",
    "        explanation = '\\n'.join(explanation_array)\n",
    "        return [estimated_total_cost, explanation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n  SELECTION\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "  SELECTION\n",
    "\"\"\"\n",
    "\n",
    "# SELECT_PART_QUERY=\"\"\"\n",
    "# SELECT p_partkey, p_name, p_mfgr, p_brand, p_type, p_size, p_container, p_retailprice, p_comment\n",
    "# FROM public.part;\n",
    "# \"\"\"\n",
    "# out = explainer.run_explain(SELECT_PART_QUERY)\n",
    "# result = explainer.analyze_execution_plan(out)\n",
    "# print(explainer.generate_report(result))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n  PROJECTION\\n  - No need to test projection of non PK columns as it will be sequential scan(covered in SELECTION)\\n  - Projection of primary key is quite complicated as it uses index-only scan.\\n    - Index only scan doesn't have a simple formula\\n      - Can derive from codebase\\n      - Instead we use this source https://postgrespro.com/blog/pgsql/5969493\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "  PROJECTION\n",
    "  - No need to test projection of non PK columns as it will be sequential scan(covered in SELECTION)\n",
    "  - Projection of primary key is quite complicated as it uses index-only scan.\n",
    "    - Index only scan doesn't have a simple formula\n",
    "      - Can derive from codebase\n",
    "      - Instead we use this source https://postgrespro.com/blog/pgsql/5969493\n",
    "\"\"\"\n",
    "# INDEX_ONLY_SCAN_QUERY = \"\"\"\n",
    "# SELECT p_partkey\n",
    "# FROM public.part;\n",
    "# \"\"\"\n",
    "\n",
    "# out = explainer.run_explain(INDEX_ONLY_SCAN_QUERY)\n",
    "# print(out)\n",
    "# result = explainer.analyze_execution_plan(out)\n",
    "# print(explainer.generate_report(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Plan': {'Node Type': 'Nested Loop', 'Parallel Aware': False, 'Async Capable': False, 'Join Type': 'Inner', 'Startup Cost': 0.0, 'Total Cost': 3.88, 'Plan Rows': 125, 'Plan Width': 864, 'Actual Startup Time': 0.091, 'Actual Total Time': 0.11, 'Actual Rows': 125, 'Actual Loops': 1, 'Inner Unique': False, 'Plans': [{'Node Type': 'Seq Scan', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Async Capable': False, 'Relation Name': 'nation', 'Alias': 'nation', 'Startup Cost': 0.0, 'Total Cost': 1.25, 'Plan Rows': 25, 'Plan Width': 434, 'Actual Startup Time': 0.046, 'Actual Total Time': 0.047, 'Actual Rows': 25, 'Actual Loops': 1}, {'Node Type': 'Materialize', 'Parent Relationship': 'Inner', 'Parallel Aware': False, 'Async Capable': False, 'Startup Cost': 0.0, 'Total Cost': 1.07, 'Plan Rows': 5, 'Plan Width': 430, 'Actual Startup Time': 0.002, 'Actual Total Time': 0.002, 'Actual Rows': 5, 'Actual Loops': 25, 'Plans': [{'Node Type': 'Seq Scan', 'Parent Relationship': 'Outer', 'Parallel Aware': False, 'Async Capable': False, 'Relation Name': 'region', 'Alias': 'region', 'Startup Cost': 0.0, 'Total Cost': 1.05, 'Plan Rows': 5, 'Plan Width': 430, 'Actual Startup Time': 0.021, 'Actual Total Time': 0.021, 'Actual Rows': 5, 'Actual Loops': 1}]}]}, 'Planning Time': 1.165, 'Triggers': [], 'Execution Time': 0.173}]\n",
      "{\n",
      "    \"Node Type\": \"Nested Loop\",\n",
      "    \"Parallel Aware\": false,\n",
      "    \"Async Capable\": false,\n",
      "    \"Join Type\": \"Inner\",\n",
      "    \"Startup Cost\": 0.0,\n",
      "    \"Total Cost\": 3.88,\n",
      "    \"Plan Rows\": 125,\n",
      "    \"Plan Width\": 864,\n",
      "    \"Actual Startup Time\": 0.091,\n",
      "    \"Actual Total Time\": 0.11,\n",
      "    \"Actual Rows\": 125,\n",
      "    \"Actual Loops\": 1,\n",
      "    \"Inner Unique\": false,\n",
      "    \"Plans\": [\n",
      "        {\n",
      "            \"Node Type\": \"Seq Scan\",\n",
      "            \"Parent Relationship\": \"Outer\",\n",
      "            \"Parallel Aware\": false,\n",
      "            \"Async Capable\": false,\n",
      "            \"Relation Name\": \"nation\",\n",
      "            \"Alias\": \"nation\",\n",
      "            \"Startup Cost\": 0.0,\n",
      "            \"Total Cost\": 1.25,\n",
      "            \"Plan Rows\": 25,\n",
      "            \"Plan Width\": 434,\n",
      "            \"Actual Startup Time\": 0.046,\n",
      "            \"Actual Total Time\": 0.047,\n",
      "            \"Actual Rows\": 25,\n",
      "            \"Actual Loops\": 1,\n",
      "            \"explanation\": \"Total cos = seq_pages_accessed(1) * seq_page_cost(1.0) + rows(25) * cpu_tuple_cost(0.01) = 1.25\",\n",
      "            \"estimated_cost\": 1.25\n",
      "        },\n",
      "        {\n",
      "            \"Node Type\": \"Materialize\",\n",
      "            \"Parent Relationship\": \"Inner\",\n",
      "            \"Parallel Aware\": false,\n",
      "            \"Async Capable\": false,\n",
      "            \"Startup Cost\": 0.0,\n",
      "            \"Total Cost\": 1.07,\n",
      "            \"Plan Rows\": 5,\n",
      "            \"Plan Width\": 430,\n",
      "            \"Actual Startup Time\": 0.002,\n",
      "            \"Actual Total Time\": 0.002,\n",
      "            \"Actual Rows\": 5,\n",
      "            \"Actual Loops\": 25,\n",
      "            \"Plans\": [\n",
      "                {\n",
      "                    \"Node Type\": \"Seq Scan\",\n",
      "                    \"Parent Relationship\": \"Outer\",\n",
      "                    \"Parallel Aware\": false,\n",
      "                    \"Async Capable\": false,\n",
      "                    \"Relation Name\": \"region\",\n",
      "                    \"Alias\": \"region\",\n",
      "                    \"Startup Cost\": 0.0,\n",
      "                    \"Total Cost\": 1.05,\n",
      "                    \"Plan Rows\": 5,\n",
      "                    \"Plan Width\": 430,\n",
      "                    \"Actual Startup Time\": 0.021,\n",
      "                    \"Actual Total Time\": 0.021,\n",
      "                    \"Actual Rows\": 5,\n",
      "                    \"Actual Loops\": 1,\n",
      "                    \"explanation\": \"Total cos = seq_pages_accessed(1) * seq_page_cost(1.0) + rows(5) * cpu_tuple_cost(0.01) = 1.05\",\n",
      "                    \"estimated_cost\": 1.05\n",
      "                }\n",
      "            ],\n",
      "            \"explanation\": \"Materialize cost = 2 * cpu_operator_cost(0.0025) * tuples(5) = 0.025\",\n",
      "            \"estimated_cost\": 1.07\n",
      "        }\n",
      "    ],\n",
      "    \"explanation\": \"Explanation for Nested Loop\\nmaterialize_cost = Cost(Seq Scan) * materialize_access_cost(1) = 1.25\\nscan_cost = 1.07\\noutput_rows_cost = output rows(125) * cpu_tuple_cost(0.01) = 1.25\\ntotal_cost = materialize_cost(1.25) + scan_cost(1.07) + output_rows_cost(1.25) = 3.5700000000000003\",\n",
      "    \"estimated_cost\": 3.57\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "  CARTESIAN PRODUCT\n",
    "  source: https://postgrespro.com/blog/pgsql/5969618\n",
    "\"\"\"\n",
    "CARTESIAN_PRODUCT_QUERY = \"\"\"\n",
    "SELECT *\n",
    "FROM public.region\n",
    "CROSS JOIN public.nation;\n",
    "\"\"\"\n",
    "\n",
    "out = explainer.run_explain(CARTESIAN_PRODUCT_QUERY)\n",
    "print(out)\n",
    "result = explainer.analyze_execution_plan(out)\n",
    "print(explainer.generate_report(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
